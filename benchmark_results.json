{
  "timestamp": "2025-11-13T23:19:28.873484",
  "checkpoint": "checkpoints/checkpoint_20000.npz",
  "config": {
    "n_layers": 8,
    "n_heads": 8,
    "d_model": 384,
    "d_ff": 1536,
    "context_length": 512,
    "vocab_size": 50257,
    "dropout": 0.1,
    "batch_size": 12,
    "learning_rate": 0.0003,
    "weight_decay": 0.1,
    "max_iters": 30000,
    "warmup_iters": 2000,
    "lr_decay_iters": 30000,
    "min_lr": 3e-05,
    "eval_interval": 500,
    "eval_iters": 50,
    "save_interval": 1000,
    "checkpoint_dir": "checkpoints",
    "dataset_name": "finewebedu",
    "max_tokens": 10000000,
    "train_split": 0.9,
    "seed": 42
  },
  "checkpoint_iteration": 20000,
  "checkpoint_loss": 0.7582720518112183,
  "memory": {
    "total_parameters": 52990464,
    "param_memory_mb_fp32": 202.142578125,
    "param_memory_mb_fp16": 101.0712890625,
    "activation_memory_mb": 843.6328125,
    "backward_memory_mb": 1687.265625,
    "per_layer_memory_mb": 56.0
  },
  "throughput": {
    "avg_latency_ms": 74.86802339553833,
    "std_latency_ms": 1.9639872950947204,
    "p50_latency_ms": 74.43368434906006,
    "p95_latency_ms": 77.39554643630981,
    "p99_latency_ms": 80.54236173629765,
    "tokens_per_second": 27354.802586147187,
    "batches_per_second": 13.356837200267181
  },
  "generation": {
    "avg_generation_latency_s": 0.5886658668518067,
    "generation_tokens_per_second": 169.87565549672755
  },
  "perplexity_validation": {
    "perplexity": 690728.1920210005,
    "loss": 13.445501670837402,
    "tokens": 1024000,
    "batches": 500,
    "time": 38.682559967041016
  },
  "benchmark_time_seconds": 55.075504779815674
}